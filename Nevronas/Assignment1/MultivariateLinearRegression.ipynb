##code written in Python 3 

## Import stuff
 
import numpy as np
from sklearn import datasets, linear_model, metrics

## Load the diabetes dataset
diabetes = datasets.load_diabetes()
diabetes_X = diabetes.data # matrix of dimensions 442x10
 
# Split the data into training/testing sets
diabetes_X_train = diabetes_X[:-20]
diabetes_X_test = diabetes_X[-20:]
 
# Split the targets into training/testing sets
diabetes_y_train = diabetes.target[:-20]
diabetes_y_test = diabetes.target[-20:]

# train

a=np.array([[1]])
for i in range(421):
    a=np.append(a,[[1]],axis=0)

X = np.append(a, diabetes_X_train,axis=1)
y = diabetes_y_train

# train: init
W = np.array([[1],[10],[10],[10],[10],[10],[10],[10000],[10],[10],[10]])

W1=W
#b = 1
 
learning_rate = 0.001
epochs = 50000
 
# train: gradient descent

for i in range(epochs):
    # calculate predictions
    predictions= np.dot(X,W)
 
    # calculate error and cost (mean squared error)
    error= np.sum((predictions-y)**2)/422
    cost= error/2
 
    # calculate gradients
    for j in range(11):
        X_mult=np.array([X[0:422,j]]).transpose()
        sigma=np.sum((np.dot(X,W)-y)*X_mult)
        W1[j]=W[j] - (learning_rate/422)*sigma
 
    # update parameters
    W1=W
 
    # diagnostic output
    if i % 100 == 0: 
        print("Epoch %d: %f" % (i, error))
        

        
## test

a=np.array([[1]])
for i in range(19):
    a=np.append(a,[[1]],axis=0)
    
X = np.append(a, diabetes_X_test,axis=1)
Y = diabetes_y_test
 
# calculate predictions + calculate error and cost (same code as above)
predictions=np.dot(X,W1)
error= np.sum((predictions-Y)**2)/20



print('Coefficients: \n', W1)
print("Mean squared error: %0.2f" % error)
print("="*120)

#############################################=Print results-#############################################
'''Coefficients: 
 [[153]
 [  0]
 [  0]
 [  0]
 [  0]
 [  0]
 [  0]
 [  0]
 [  0]
 [  0]
 [  0]]
Mean squared error: 110988.00
========================================================================================================================'''